[Global]

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')   # Sets up the conda device this code will use
personal = True                                                         # True if training a personal model. False if you want to train ANI1x or ANI2x
netlike1x = False                                                       # True if your networks have an architecture like ANI1x
netlike2x = True                                                        # True if your networks have an architecture like ANI2x
functional = wb97x                                                    	# Functional used to compute the training set
basis_set = 631gd                                                     	# Basis set used to compute the training set
constants = None                                                        # Path to constants file if getting AEV params from a separate file (modifications must be made to protocol if you want to use key)
elements = ['H', 'C', 'N', 'O', 'S', 'F', 'Cl']                         # List of elements in you data; this specifies species order; should match 1x and 2x allowed atoms
gsae_dat = None                                                         # Path to file containing GSAE values, if not getting them from torchani
activation = torch.nn.GELU()                                            # Activation function you are using
bias = False                                                            # Specifies whether or not you are using biases in your networks
classifier_out = 1                                                      # Number of outputs of your network


[Trainer]

forces = False								# True if you are training to forces
charges = False								# True if you are training to charges
dipole = False								# True if you are training to dipoles
batch_size = 2048							# Specified batch size
ds_path = None								# Path to your batched data sets, if using
h5_path = None								# Path to your original h5 files. Used if you havent batched yet, or are not batching your data
include_properties = ['energies', 'species', 'coordinates']		# Properties in your data set you want to include in your training and validation 
logdir = logs/								# Path to your the directory that contains your trained networks 
projectlabel = None							# Unique name of your project, used for saving purposes
train_file  = os.path.abspath(__file__)					# Keep as is. This is used to copy this file to your logs
now = datetime.datetime.now()						# Datetime used to properly label your project 
data_split = {'training': 0.8, 'validation': 0.2}			# Training and validation percentage split
num_tasks = 2								# Number of tasks if using MTLLoss 
weight_decay = [6.1E-5, None, None, None]				# List corresponding to weigh decay by layer
lr_factor = 0.7								# ReduceLROnPlateau factor
lr_patience = 14							# ReduceLROnPlateau patience
lr_threshold = 0.0006							# ReduceLROnPlateau threshold
max_epochs = 2000							# Max number of epochs until termination
early_stopping_learning_rate = 1.0E-7					# Learning rate to terminate training
restarting = False							# True if restarting training from existing pt file


